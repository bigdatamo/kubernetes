{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "authentic-sierra",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as Fq\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import countDistinct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "brazilian-medline",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 300)\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "controversial-upset",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, StratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve, auc, make_scorer, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "honey-conjunction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyspark.sql.session.SparkSession object at 0x7fe98b68e860>\n",
      "CPU times: user 21.1 ms, sys: 22.5 ms, total: 43.6 ms\n",
      "Wall time: 32.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# spark session\n",
    "os.environ['SPARK_HOME'] = \"/opt/cloudera/parcels/CDH/lib/spark/\"\n",
    "os.environ['PYSPARK_PYTHON'] = '/opt/cloudera/parcels/Anaconda/envs/py36/bin/python'\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = '/opt/cloudera/parcels/Anaconda/envs/py36/bin/python'\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"yarn\") \\\n",
    "    .appName(\"test\") \\\n",
    "    .enableHiveSupport() \\\n",
    "    .config(\"spark.submit.deployMode\",\"client\") \\\n",
    "    .config(\"spark.yarn.appMasterEnv.PYSPARK_PYTHON\",\"/opt/cloudera/parcels/Anaconda/envs/py36/bin/python\") \\\n",
    "    .config(\"spark.yarn.appMasterEnv.PYSPARK_DRIVER_PYTHON\",\"/opt/cloudera/parcels/Anaconda/envs/py36/bin/python\") \\\n",
    "    .config(\"spark.driver.memory\",\"8g\") \\\n",
    "    .config(\"spark.executor.memory\",\"16g\") \\\n",
    "    .getOrCreate()\n",
    "print(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "other-croatia",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "def generate_dates():\n",
    "    start_date = datetime.strptime('2022-08-01', '%Y-%m-%d')\n",
    "    end_date = datetime.strptime('2023-09-01', '%Y-%m-%d')\n",
    "    current_date = start_date\n",
    "    date_list = []\n",
    "\n",
    "    while current_date <= end_date:\n",
    "        date_list.append(current_date.strftime('%Y-%m-%d'))\n",
    "        # Increment by one month\n",
    "        if current_date.month == 12:\n",
    "            current_date = current_date.replace(year=current_date.year+1, month=1)\n",
    "        else:\n",
    "            current_date = current_date.replace(month=current_date.month+1)\n",
    "\n",
    "    return date_list\n",
    "\n",
    "dates = generate_dates()\n",
    "\n",
    "tables = ['exp_clr_balance_v2', 'exp_data_v2', 'exp_device_v2', 'exp_interco_v2', 'exp_prep_arpu_v2', 'exp_parc_prep_v2', \n",
    "          'exp_pass_v2', 'exp_rech_v2', 'exp_roam_v2', 'exp_vas_v2', 'exp_voix_v2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "tribal-feeling",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2022-08-01',\n",
       " '2022-09-01',\n",
       " '2022-10-01',\n",
       " '2022-11-01',\n",
       " '2022-12-01',\n",
       " '2023-01-01',\n",
       " '2023-02-01',\n",
       " '2023-03-01',\n",
       " '2023-04-01',\n",
       " '2023-05-01',\n",
       " '2023-06-01',\n",
       " '2023-07-01',\n",
       " '2023-08-01',\n",
       " '2023-09-01']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "proof-board",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 3 \n",
    "\n",
    "date_start = dates[k]\n",
    "date_end = dates[k+1]\n",
    "date_final_obs = dates[k+3]\n",
    "date_data_origin = dates[k-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "governmental-alarm",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2022-11-01', '2022-12-01', '2023-02-01', '2022-08-01']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = [date_start, date_end, date_final_obs, date_data_origin]\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "daily-corner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0------------------------------------\n",
      " final_anon_mdn       | 29010156965826191... \n",
      " event_time           | 2023-01-16 22:40:02  \n",
      " profile_id           | 84001                \n",
      " segment              | B2C                  \n",
      " formule              | Prepaid              \n",
      " desc_profil          | TicTac 4G            \n",
      " produit              | TicTac 4G            \n",
      " gamme                | TicTac               \n",
      " marche               | Mobile Prepaid       \n",
      " balance_debit_before | 200                  \n",
      " balance_debit_after  | 0                    \n",
      " account_type_id_1    | 5121                 \n",
      " bal1_descr           | DATA                 \n",
      " bal1_unit            | MO                   \n",
      " bal1_revenue_flag    | N                    \n",
      " account_type_id_2    | 5201                 \n",
      " bal2_descr           | Report DATA          \n",
      " bal2_unit            | MO                   \n",
      " bal2_revenue_flag    | N                    \n",
      " account_type_id_3    |                      \n",
      " bal3_descr           | null                 \n",
      " bal3_unit            | null                 \n",
      " bal3_revenue_flag    | null                 \n",
      " account_type_id_4    |                      \n",
      " bal4_descr           | null                 \n",
      " bal4_unit            | null                 \n",
      " bal4_revenue_flag    | null                 \n",
      " account_type_id_5    |                      \n",
      " bal5_descr           | null                 \n",
      " bal5_unit            | null                 \n",
      " bal5_revenue_flag    | null                 \n",
      " account_type_id_6    |                      \n",
      " bal6_descr           | null                 \n",
      " bal6_unit            | null                 \n",
      " bal6_revenue_flag    | null                 \n",
      " amount_debited_1     | 200000000            \n",
      " amount_debited_2     | 4                    \n",
      " amount_debited_3     | null                 \n",
      " amount_debited_4     | null                 \n",
      " amount_debited_5     | null                 \n",
      " amount_debited_6     | null                 \n",
      " balance_ab_normal    |                      \n",
      " status               | 0                    \n",
      " recharge_channel     | 4                    \n",
      " access_method        | 3                    \n",
      " cust_level           | 1                    \n",
      " recharge_time        | 2023-01-16 22:39:50  \n",
      " recharge_value       | 500                  \n",
      " recharge_type        | 1                    \n",
      " star_code            | 3                    \n",
      " trade_type           | 7                    \n",
      " price_before         | null                 \n",
      " price_after          | null                 \n",
      " initial_price        | null                 \n",
      " initial_debt         | null                 \n",
      " scoring_id           | null                 \n",
      " ingestion_timestamp  | 20230116221001       \n",
      " ingestion_date       | 20230116             \n",
      " filename             | Remb_rech_230116_... \n",
      " event_date           | 20230116             \n",
      "-RECORD 1------------------------------------\n",
      " final_anon_mdn       | 24470880220971245... \n",
      " event_time           | 2023-01-16 22:18:50  \n",
      " profile_id           | 5291                 \n",
      " segment              | B2C                  \n",
      " formule              | Prepaid              \n",
      " desc_profil          | TicTac               \n",
      " produit              | TicTac               \n",
      " gamme                | TicTac               \n",
      " marche               | Mobile Prepaid       \n",
      " balance_debit_before | 200                  \n",
      " balance_debit_after  | 0                    \n",
      " account_type_id_1    | 5121                 \n",
      " bal1_descr           | DATA                 \n",
      " bal1_unit            | MO                   \n",
      " bal1_revenue_flag    | N                    \n",
      " account_type_id_2    |                      \n",
      " bal2_descr           | null                 \n",
      " bal2_unit            | null                 \n",
      " bal2_revenue_flag    | null                 \n",
      " account_type_id_3    |                      \n",
      " bal3_descr           | null                 \n",
      " bal3_unit            | null                 \n",
      " bal3_revenue_flag    | null                 \n",
      " account_type_id_4    |                      \n",
      " bal4_descr           | null                 \n",
      " bal4_unit            | null                 \n",
      " bal4_revenue_flag    | null                 \n",
      " account_type_id_5    |                      \n",
      " bal5_descr           | null                 \n",
      " bal5_unit            | null                 \n",
      " bal5_revenue_flag    | null                 \n",
      " account_type_id_6    |                      \n",
      " bal6_descr           | null                 \n",
      " bal6_unit            | null                 \n",
      " bal6_revenue_flag    | null                 \n",
      " amount_debited_1     | 200000113            \n",
      " amount_debited_2     | null                 \n",
      " amount_debited_3     | null                 \n",
      " amount_debited_4     | null                 \n",
      " amount_debited_5     | null                 \n",
      " amount_debited_6     | null                 \n",
      " balance_ab_normal    |                      \n",
      " status               | 0                    \n",
      " recharge_channel     | -1                   \n",
      " access_method        | 3                    \n",
      " cust_level           | 4050376              \n",
      " recharge_time        | 2023-01-16 22:18:34  \n",
      " recharge_value       | 500                  \n",
      " recharge_type        | 1                    \n",
      " star_code            | 3                    \n",
      " trade_type           | 7                    \n",
      " price_before         | null                 \n",
      " price_after          | null                 \n",
      " initial_price        | null                 \n",
      " initial_debt         | null                 \n",
      " scoring_id           | null                 \n",
      " ingestion_timestamp  | 20230116221001       \n",
      " ingestion_date       | 20230116             \n",
      " filename             | Remb_rech_230116_... \n",
      " event_date           | 20230116             \n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "exp_sdp_remboursement_recharge_v2 = spark.sql(f\"\"\"SELECT * \n",
    "FROM \n",
    "tel_test_avrd.exp_sdp_remboursement_recharge_v2 \n",
    "WHERE event_time >= '{date_start}' AND event_time < '{date_final_obs}'\"\"\")\n",
    "exp_sdp_remboursement_recharge_v2.show(n=2, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "suspected-mentor",
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o120.showString.\n: org.apache.spark.SparkException: Job 3 cancelled because SparkContext was shut down\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanUpAfterSchedulerStop$1.apply(DAGScheduler.scala:935)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanUpAfterSchedulerStop$1.apply(DAGScheduler.scala:933)\n\tat scala.collection.mutable.HashSet.foreach(HashSet.scala:78)\n\tat org.apache.spark.scheduler.DAGScheduler.cleanUpAfterSchedulerStop(DAGScheduler.scala:933)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onStop(DAGScheduler.scala:2129)\n\tat org.apache.spark.util.EventLoop.stop(EventLoop.scala:84)\n\tat org.apache.spark.scheduler.DAGScheduler.stop(DAGScheduler.scala:2042)\n\tat org.apache.spark.SparkContext$$anonfun$stop$7.apply$mcV$sp(SparkContext.scala:1963)\n\tat org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1388)\n\tat org.apache.spark.SparkContext.stop(SparkContext.scala:1962)\n\tat org.apache.spark.scheduler.cluster.YarnClientSchedulerBackend$MonitorThread.run(YarnClientSchedulerBackend.scala:122)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:740)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2081)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2102)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2121)\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:365)\n\tat org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:38)\n\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$collectFromPlan(Dataset.scala:3383)\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2544)\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2544)\n\tat org.apache.spark.sql.Dataset$$anonfun$53.apply(Dataset.scala:3364)\n\tat org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:78)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:125)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:73)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3363)\n\tat org.apache.spark.sql.Dataset.head(Dataset.scala:2544)\n\tat org.apache.spark.sql.Dataset.take(Dataset.scala:2758)\n\tat org.apache.spark.sql.Dataset.getRows(Dataset.scala:254)\n\tat org.apache.spark.sql.Dataset.showString(Dataset.scala:291)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-840aaf042664>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mWHERE\u001b[0m \u001b[0mtimestamp\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;34m'{date_start}'\u001b[0m \u001b[0mAND\u001b[0m \u001b[0mtimestamp\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m'{date_end}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     ORDER BY RAND() LIMIT 100000\"\"\")\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mexp_sdp_avr_v2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/cloudera/parcels/Anaconda/envs/py36/lib/python3.6/site-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    376\u001b[0m         \"\"\"\n\u001b[1;32m    377\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtruncate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/cloudera/parcels/Anaconda/envs/py36/lib/python3.6/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1305\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1307\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/cloudera/parcels/Anaconda/envs/py36/lib/python3.6/site-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/cloudera/parcels/Anaconda/envs/py36/lib/python3.6/site-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o120.showString.\n: org.apache.spark.SparkException: Job 3 cancelled because SparkContext was shut down\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanUpAfterSchedulerStop$1.apply(DAGScheduler.scala:935)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanUpAfterSchedulerStop$1.apply(DAGScheduler.scala:933)\n\tat scala.collection.mutable.HashSet.foreach(HashSet.scala:78)\n\tat org.apache.spark.scheduler.DAGScheduler.cleanUpAfterSchedulerStop(DAGScheduler.scala:933)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onStop(DAGScheduler.scala:2129)\n\tat org.apache.spark.util.EventLoop.stop(EventLoop.scala:84)\n\tat org.apache.spark.scheduler.DAGScheduler.stop(DAGScheduler.scala:2042)\n\tat org.apache.spark.SparkContext$$anonfun$stop$7.apply$mcV$sp(SparkContext.scala:1963)\n\tat org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1388)\n\tat org.apache.spark.SparkContext.stop(SparkContext.scala:1962)\n\tat org.apache.spark.scheduler.cluster.YarnClientSchedulerBackend$MonitorThread.run(YarnClientSchedulerBackend.scala:122)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:740)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2081)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2102)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2121)\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:365)\n\tat org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:38)\n\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$collectFromPlan(Dataset.scala:3383)\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2544)\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2544)\n\tat org.apache.spark.sql.Dataset$$anonfun$53.apply(Dataset.scala:3364)\n\tat org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:78)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:125)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:73)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3363)\n\tat org.apache.spark.sql.Dataset.head(Dataset.scala:2544)\n\tat org.apache.spark.sql.Dataset.take(Dataset.scala:2758)\n\tat org.apache.spark.sql.Dataset.getRows(Dataset.scala:254)\n\tat org.apache.spark.sql.Dataset.showString(Dataset.scala:291)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n"
     ]
    }
   ],
   "source": [
    "exp_sdp_avr_v2 = spark.sql(f\"\"\"SELECT * \n",
    "    FROM tel_test_avrd.exp_sdp_avr_v2 \n",
    "    WHERE timestamp >= '{date_start}' AND timestamp < '{date_end}' \n",
    "    ORDER BY RAND() LIMIT 100000\"\"\")\n",
    "exp_sdp_avr_v2.show(n=2, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "municipal-notion",
   "metadata": {},
   "outputs": [],
   "source": [
    "avr_reimbursement = exp_sdp_avr_v2.join(exp_sdp_remboursement_recharge_v2, 'final_anon_mdn', how='left').select('final_anon_mdn', 'timestamp', 'event_time').toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "national-click",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "center-tomato",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>final_anon_mdn</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>event_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0009199021916181057050608</td>\n",
       "      <td>2022-11-08 09:38:12.0</td>\n",
       "      <td>2022-12-02 19:58:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0009199021916181057050608</td>\n",
       "      <td>2022-11-08 09:38:12.0</td>\n",
       "      <td>2022-11-07 20:41:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0009199021916181057050608</td>\n",
       "      <td>2022-11-08 09:38:12.0</td>\n",
       "      <td>2022-12-30 18:43:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0009199021916181057050608</td>\n",
       "      <td>2022-11-08 09:38:12.0</td>\n",
       "      <td>2022-11-20 16:05:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0009199021916181057050608</td>\n",
       "      <td>2022-11-08 09:38:12.0</td>\n",
       "      <td>2022-11-16 16:41:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0009199021916181057050608</td>\n",
       "      <td>2022-11-08 09:38:12.0</td>\n",
       "      <td>2022-12-08 11:12:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0009199021916181057050608</td>\n",
       "      <td>2022-11-08 09:38:12.0</td>\n",
       "      <td>2022-12-27 13:52:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0009199021916181057050608</td>\n",
       "      <td>2022-11-08 09:38:12.0</td>\n",
       "      <td>2022-12-05 14:22:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0009199021916181057050608</td>\n",
       "      <td>2022-11-08 09:38:12.0</td>\n",
       "      <td>2022-11-10 21:26:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0009199021916181057050608</td>\n",
       "      <td>2022-11-08 09:38:12.0</td>\n",
       "      <td>2022-12-16 16:18:18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              final_anon_mdn              timestamp          event_time\n",
       "0  0009199021916181057050608  2022-11-08 09:38:12.0 2022-12-02 19:58:09\n",
       "1  0009199021916181057050608  2022-11-08 09:38:12.0 2022-11-07 20:41:35\n",
       "2  0009199021916181057050608  2022-11-08 09:38:12.0 2022-12-30 18:43:51\n",
       "3  0009199021916181057050608  2022-11-08 09:38:12.0 2022-11-20 16:05:31\n",
       "4  0009199021916181057050608  2022-11-08 09:38:12.0 2022-11-16 16:41:17\n",
       "5  0009199021916181057050608  2022-11-08 09:38:12.0 2022-12-08 11:12:38\n",
       "6  0009199021916181057050608  2022-11-08 09:38:12.0 2022-12-27 13:52:08\n",
       "7  0009199021916181057050608  2022-11-08 09:38:12.0 2022-12-05 14:22:23\n",
       "8  0009199021916181057050608  2022-11-08 09:38:12.0 2022-11-10 21:26:31\n",
       "9  0009199021916181057050608  2022-11-08 09:38:12.0 2022-12-16 16:18:18"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avr_reimbursement.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "valuable-cheat",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "988061"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(avr_reimbursement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "confident-committee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>final_anon_mdn</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>event_time</th>\n",
       "      <th>reinbursement_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0009199021916181057050608</td>\n",
       "      <td>2022-11-08 09:38:12</td>\n",
       "      <td>2022-12-02 19:58:09</td>\n",
       "      <td>2022-12-02 19:58:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0009199021916181057050608</td>\n",
       "      <td>2022-11-08 09:38:12</td>\n",
       "      <td>2022-11-07 20:41:35</td>\n",
       "      <td>2023-02-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0009199021916181057050608</td>\n",
       "      <td>2022-11-08 09:38:12</td>\n",
       "      <td>2022-12-30 18:43:51</td>\n",
       "      <td>2022-12-30 18:43:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0009199021916181057050608</td>\n",
       "      <td>2022-11-08 09:38:12</td>\n",
       "      <td>2022-11-20 16:05:31</td>\n",
       "      <td>2022-11-20 16:05:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0009199021916181057050608</td>\n",
       "      <td>2022-11-08 09:38:12</td>\n",
       "      <td>2022-11-16 16:41:17</td>\n",
       "      <td>2022-11-16 16:41:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0009199021916181057050608</td>\n",
       "      <td>2022-11-08 09:38:12</td>\n",
       "      <td>2022-12-08 11:12:38</td>\n",
       "      <td>2022-12-08 11:12:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0009199021916181057050608</td>\n",
       "      <td>2022-11-08 09:38:12</td>\n",
       "      <td>2022-12-27 13:52:08</td>\n",
       "      <td>2022-12-27 13:52:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0009199021916181057050608</td>\n",
       "      <td>2022-11-08 09:38:12</td>\n",
       "      <td>2022-12-05 14:22:23</td>\n",
       "      <td>2022-12-05 14:22:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0009199021916181057050608</td>\n",
       "      <td>2022-11-08 09:38:12</td>\n",
       "      <td>2022-11-10 21:26:31</td>\n",
       "      <td>2022-11-10 21:26:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0009199021916181057050608</td>\n",
       "      <td>2022-11-08 09:38:12</td>\n",
       "      <td>2022-12-16 16:18:18</td>\n",
       "      <td>2022-12-16 16:18:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0009199021916181057050608</td>\n",
       "      <td>2022-11-08 09:38:12</td>\n",
       "      <td>2022-11-05 18:27:18</td>\n",
       "      <td>2023-02-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0009199021916181057050608</td>\n",
       "      <td>2022-11-08 09:38:12</td>\n",
       "      <td>2022-12-13 22:02:31</td>\n",
       "      <td>2022-12-13 22:02:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0009199021916181057050608</td>\n",
       "      <td>2022-11-08 09:38:12</td>\n",
       "      <td>2022-12-17 13:16:38</td>\n",
       "      <td>2022-12-17 13:16:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0009199021916181057050608</td>\n",
       "      <td>2022-11-08 09:38:12</td>\n",
       "      <td>2023-01-01 16:21:26</td>\n",
       "      <td>2023-01-01 16:21:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0009199021916181057050608</td>\n",
       "      <td>2022-11-08 09:38:12</td>\n",
       "      <td>2022-12-15 22:04:33</td>\n",
       "      <td>2022-12-15 22:04:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0009199021916181057050608</td>\n",
       "      <td>2022-11-08 09:38:12</td>\n",
       "      <td>2022-12-20 23:27:15</td>\n",
       "      <td>2022-12-20 23:27:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0009199021916181057050608</td>\n",
       "      <td>2022-11-08 09:38:12</td>\n",
       "      <td>2022-11-27 17:06:07</td>\n",
       "      <td>2022-11-27 17:06:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0009199021916181057050608</td>\n",
       "      <td>2022-11-08 09:38:12</td>\n",
       "      <td>2023-01-03 16:11:52</td>\n",
       "      <td>2023-01-03 16:11:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0009199021916181057050608</td>\n",
       "      <td>2022-11-08 09:38:12</td>\n",
       "      <td>2022-12-11 22:39:33</td>\n",
       "      <td>2022-12-11 22:39:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0009199021916181057050608</td>\n",
       "      <td>2022-11-08 09:38:12</td>\n",
       "      <td>2022-11-03 20:23:26</td>\n",
       "      <td>2023-02-01 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               final_anon_mdn           timestamp          event_time  \\\n",
       "0   0009199021916181057050608 2022-11-08 09:38:12 2022-12-02 19:58:09   \n",
       "1   0009199021916181057050608 2022-11-08 09:38:12 2022-11-07 20:41:35   \n",
       "2   0009199021916181057050608 2022-11-08 09:38:12 2022-12-30 18:43:51   \n",
       "3   0009199021916181057050608 2022-11-08 09:38:12 2022-11-20 16:05:31   \n",
       "4   0009199021916181057050608 2022-11-08 09:38:12 2022-11-16 16:41:17   \n",
       "5   0009199021916181057050608 2022-11-08 09:38:12 2022-12-08 11:12:38   \n",
       "6   0009199021916181057050608 2022-11-08 09:38:12 2022-12-27 13:52:08   \n",
       "7   0009199021916181057050608 2022-11-08 09:38:12 2022-12-05 14:22:23   \n",
       "8   0009199021916181057050608 2022-11-08 09:38:12 2022-11-10 21:26:31   \n",
       "9   0009199021916181057050608 2022-11-08 09:38:12 2022-12-16 16:18:18   \n",
       "10  0009199021916181057050608 2022-11-08 09:38:12 2022-11-05 18:27:18   \n",
       "11  0009199021916181057050608 2022-11-08 09:38:12 2022-12-13 22:02:31   \n",
       "12  0009199021916181057050608 2022-11-08 09:38:12 2022-12-17 13:16:38   \n",
       "13  0009199021916181057050608 2022-11-08 09:38:12 2023-01-01 16:21:26   \n",
       "14  0009199021916181057050608 2022-11-08 09:38:12 2022-12-15 22:04:33   \n",
       "15  0009199021916181057050608 2022-11-08 09:38:12 2022-12-20 23:27:15   \n",
       "16  0009199021916181057050608 2022-11-08 09:38:12 2022-11-27 17:06:07   \n",
       "17  0009199021916181057050608 2022-11-08 09:38:12 2023-01-03 16:11:52   \n",
       "18  0009199021916181057050608 2022-11-08 09:38:12 2022-12-11 22:39:33   \n",
       "19  0009199021916181057050608 2022-11-08 09:38:12 2022-11-03 20:23:26   \n",
       "\n",
       "    reinbursement_time  \n",
       "0  2022-12-02 19:58:09  \n",
       "1  2023-02-01 00:00:00  \n",
       "2  2022-12-30 18:43:51  \n",
       "3  2022-11-20 16:05:31  \n",
       "4  2022-11-16 16:41:17  \n",
       "5  2022-12-08 11:12:38  \n",
       "6  2022-12-27 13:52:08  \n",
       "7  2022-12-05 14:22:23  \n",
       "8  2022-11-10 21:26:31  \n",
       "9  2022-12-16 16:18:18  \n",
       "10 2023-02-01 00:00:00  \n",
       "11 2022-12-13 22:02:31  \n",
       "12 2022-12-17 13:16:38  \n",
       "13 2023-01-01 16:21:26  \n",
       "14 2022-12-15 22:04:33  \n",
       "15 2022-12-20 23:27:15  \n",
       "16 2022-11-27 17:06:07  \n",
       "17 2023-01-03 16:11:52  \n",
       "18 2022-12-11 22:39:33  \n",
       "19 2023-02-01 00:00:00  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avr_reimbursement['timestamp'] = pd.to_datetime(avr_reimbursement['timestamp'])\n",
    "avr_reimbursement['reinbursement_time'] = avr_reimbursement.apply(\n",
    "    lambda row: date_final_obs if (pd.isnull(row['event_time']) or row['event_time'] < row['timestamp']) \n",
    "    else row['event_time'], axis=1)\n",
    "avr_reimbursement.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "specified-duration",
   "metadata": {},
   "outputs": [],
   "source": [
    "avr_reimbursement['date_diff'] = pd.to_datetime(avr_reimbursement['reinbursement_time']) - pd.to_datetime(avr_reimbursement['timestamp'])\n",
    "avr_reimbursement['date_diff'] = avr_reimbursement['date_diff'].dt.days\n",
    "avr_reimbursement['flag'] = (avr_reimbursement['date_diff'] <= 45).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "unusual-pricing",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>final_anon_mdn</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>event_time</th>\n",
       "      <th>reinbursement_time</th>\n",
       "      <th>date_diff</th>\n",
       "      <th>flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0009199021916181057050608</td>\n",
       "      <td>2022-11-08 09:38:12</td>\n",
       "      <td>2022-12-02 19:58:09</td>\n",
       "      <td>2022-12-02 19:58:09</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0009199021916181057050608</td>\n",
       "      <td>2022-11-08 09:38:12</td>\n",
       "      <td>2022-11-07 20:41:35</td>\n",
       "      <td>2023-02-01 00:00:00</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0009199021916181057050608</td>\n",
       "      <td>2022-11-08 09:38:12</td>\n",
       "      <td>2022-12-30 18:43:51</td>\n",
       "      <td>2022-12-30 18:43:51</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0009199021916181057050608</td>\n",
       "      <td>2022-11-08 09:38:12</td>\n",
       "      <td>2022-11-20 16:05:31</td>\n",
       "      <td>2022-11-20 16:05:31</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0009199021916181057050608</td>\n",
       "      <td>2022-11-08 09:38:12</td>\n",
       "      <td>2022-11-16 16:41:17</td>\n",
       "      <td>2022-11-16 16:41:17</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0009199021916181057050608</td>\n",
       "      <td>2022-11-08 09:38:12</td>\n",
       "      <td>2022-12-08 11:12:38</td>\n",
       "      <td>2022-12-08 11:12:38</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0009199021916181057050608</td>\n",
       "      <td>2022-11-08 09:38:12</td>\n",
       "      <td>2022-12-27 13:52:08</td>\n",
       "      <td>2022-12-27 13:52:08</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0009199021916181057050608</td>\n",
       "      <td>2022-11-08 09:38:12</td>\n",
       "      <td>2022-12-05 14:22:23</td>\n",
       "      <td>2022-12-05 14:22:23</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0009199021916181057050608</td>\n",
       "      <td>2022-11-08 09:38:12</td>\n",
       "      <td>2022-11-10 21:26:31</td>\n",
       "      <td>2022-11-10 21:26:31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0009199021916181057050608</td>\n",
       "      <td>2022-11-08 09:38:12</td>\n",
       "      <td>2022-12-16 16:18:18</td>\n",
       "      <td>2022-12-16 16:18:18</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0009199021916181057050608</td>\n",
       "      <td>2022-11-08 09:38:12</td>\n",
       "      <td>2022-11-05 18:27:18</td>\n",
       "      <td>2023-02-01 00:00:00</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0009199021916181057050608</td>\n",
       "      <td>2022-11-08 09:38:12</td>\n",
       "      <td>2022-12-13 22:02:31</td>\n",
       "      <td>2022-12-13 22:02:31</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0009199021916181057050608</td>\n",
       "      <td>2022-11-08 09:38:12</td>\n",
       "      <td>2022-12-17 13:16:38</td>\n",
       "      <td>2022-12-17 13:16:38</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0009199021916181057050608</td>\n",
       "      <td>2022-11-08 09:38:12</td>\n",
       "      <td>2023-01-01 16:21:26</td>\n",
       "      <td>2023-01-01 16:21:26</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0009199021916181057050608</td>\n",
       "      <td>2022-11-08 09:38:12</td>\n",
       "      <td>2022-12-15 22:04:33</td>\n",
       "      <td>2022-12-15 22:04:33</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0009199021916181057050608</td>\n",
       "      <td>2022-11-08 09:38:12</td>\n",
       "      <td>2022-12-20 23:27:15</td>\n",
       "      <td>2022-12-20 23:27:15</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0009199021916181057050608</td>\n",
       "      <td>2022-11-08 09:38:12</td>\n",
       "      <td>2022-11-27 17:06:07</td>\n",
       "      <td>2022-11-27 17:06:07</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0009199021916181057050608</td>\n",
       "      <td>2022-11-08 09:38:12</td>\n",
       "      <td>2023-01-03 16:11:52</td>\n",
       "      <td>2023-01-03 16:11:52</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0009199021916181057050608</td>\n",
       "      <td>2022-11-08 09:38:12</td>\n",
       "      <td>2022-12-11 22:39:33</td>\n",
       "      <td>2022-12-11 22:39:33</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0009199021916181057050608</td>\n",
       "      <td>2022-11-08 09:38:12</td>\n",
       "      <td>2022-11-03 20:23:26</td>\n",
       "      <td>2023-02-01 00:00:00</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0042093647936468925916828</td>\n",
       "      <td>2022-11-22 13:03:39</td>\n",
       "      <td>2023-01-20 23:01:40</td>\n",
       "      <td>2023-01-20 23:01:40</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0042093647936468925916828</td>\n",
       "      <td>2022-11-22 13:03:39</td>\n",
       "      <td>2022-12-07 23:25:00</td>\n",
       "      <td>2022-12-07 23:25:00</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0042093647936468925916828</td>\n",
       "      <td>2022-11-22 13:03:39</td>\n",
       "      <td>2022-11-06 15:28:40</td>\n",
       "      <td>2023-02-01 00:00:00</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0042093647936468925916828</td>\n",
       "      <td>2022-11-22 13:03:39</td>\n",
       "      <td>2022-11-01 18:34:59</td>\n",
       "      <td>2023-02-01 00:00:00</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0042093647936468925916828</td>\n",
       "      <td>2022-11-22 13:03:39</td>\n",
       "      <td>2022-11-28 22:12:48</td>\n",
       "      <td>2022-11-28 22:12:48</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0042093647936468925916828</td>\n",
       "      <td>2022-11-22 13:03:39</td>\n",
       "      <td>2022-12-05 22:37:17</td>\n",
       "      <td>2022-12-05 22:37:17</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0042093647936468925916828</td>\n",
       "      <td>2022-11-22 13:03:39</td>\n",
       "      <td>2022-12-12 23:03:02</td>\n",
       "      <td>2022-12-12 23:03:02</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0042093647936468925916828</td>\n",
       "      <td>2022-11-22 13:03:39</td>\n",
       "      <td>2022-12-24 17:07:25</td>\n",
       "      <td>2022-12-24 17:07:25</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0042093647936468925916828</td>\n",
       "      <td>2022-11-22 13:03:39</td>\n",
       "      <td>2023-01-05 12:29:56</td>\n",
       "      <td>2023-01-05 12:29:56</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0042093647936468925916828</td>\n",
       "      <td>2022-11-22 13:03:39</td>\n",
       "      <td>2023-01-26 04:44:20</td>\n",
       "      <td>2023-01-26 04:44:20</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0042093647936468925916828</td>\n",
       "      <td>2022-11-22 13:03:39</td>\n",
       "      <td>2022-11-14 23:03:10</td>\n",
       "      <td>2023-02-01 00:00:00</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0042093647936468925916828</td>\n",
       "      <td>2022-11-22 13:03:39</td>\n",
       "      <td>2022-12-18 15:07:01</td>\n",
       "      <td>2022-12-18 15:07:01</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0042093647936468925916828</td>\n",
       "      <td>2022-11-22 13:03:39</td>\n",
       "      <td>2022-11-19 20:15:59</td>\n",
       "      <td>2023-02-01 00:00:00</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0042093647936468925916828</td>\n",
       "      <td>2022-11-22 13:03:39</td>\n",
       "      <td>2022-12-16 14:10:03</td>\n",
       "      <td>2022-12-16 14:10:03</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0042093647936468925916828</td>\n",
       "      <td>2022-11-22 13:03:39</td>\n",
       "      <td>2023-01-19 00:23:40</td>\n",
       "      <td>2023-01-19 00:23:40</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0042093647936468925916828</td>\n",
       "      <td>2022-11-22 13:03:39</td>\n",
       "      <td>2023-01-07 00:05:02</td>\n",
       "      <td>2023-01-07 00:05:02</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0042093647936468925916828</td>\n",
       "      <td>2022-11-22 13:03:39</td>\n",
       "      <td>2022-11-11 16:23:23</td>\n",
       "      <td>2023-02-01 00:00:00</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0042093647936468925916828</td>\n",
       "      <td>2022-11-22 13:03:39</td>\n",
       "      <td>2022-11-02 12:03:39</td>\n",
       "      <td>2023-02-01 00:00:00</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0042093647936468925916828</td>\n",
       "      <td>2022-11-22 13:03:39</td>\n",
       "      <td>2023-01-08 01:30:06</td>\n",
       "      <td>2023-01-08 01:30:06</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0042093647936468925916828</td>\n",
       "      <td>2022-11-22 13:03:39</td>\n",
       "      <td>2022-12-06 23:58:37</td>\n",
       "      <td>2022-12-06 23:58:37</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0042093647936468925916828</td>\n",
       "      <td>2022-11-22 13:03:39</td>\n",
       "      <td>2022-11-13 20:15:56</td>\n",
       "      <td>2023-02-01 00:00:00</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0042093647936468925916828</td>\n",
       "      <td>2022-11-22 13:03:39</td>\n",
       "      <td>2023-01-27 20:33:02</td>\n",
       "      <td>2023-01-27 20:33:02</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0042093647936468925916828</td>\n",
       "      <td>2022-11-22 13:03:39</td>\n",
       "      <td>2022-12-14 23:22:12</td>\n",
       "      <td>2022-12-14 23:22:12</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0042093647936468925916828</td>\n",
       "      <td>2022-11-22 13:03:39</td>\n",
       "      <td>2023-01-24 22:50:17</td>\n",
       "      <td>2023-01-24 22:50:17</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0042093647936468925916828</td>\n",
       "      <td>2022-11-22 13:03:39</td>\n",
       "      <td>2023-01-03 19:04:29</td>\n",
       "      <td>2023-01-03 19:04:29</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0042093647936468925916828</td>\n",
       "      <td>2022-11-22 13:03:39</td>\n",
       "      <td>2022-12-11 14:45:34</td>\n",
       "      <td>2022-12-11 14:45:34</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0042093647936468925916828</td>\n",
       "      <td>2022-11-22 13:03:39</td>\n",
       "      <td>2022-11-03 11:28:55</td>\n",
       "      <td>2023-02-01 00:00:00</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0042093647936468925916828</td>\n",
       "      <td>2022-11-22 13:03:39</td>\n",
       "      <td>2022-11-03 22:44:33</td>\n",
       "      <td>2023-02-01 00:00:00</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0056047737941475902994905</td>\n",
       "      <td>2022-11-25 20:06:08</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2023-02-01 00:00:00</td>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0065077430527166987904116</td>\n",
       "      <td>2022-11-25 04:32:27</td>\n",
       "      <td>2022-11-01 03:16:42</td>\n",
       "      <td>2023-02-01 00:00:00</td>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0065077430527166987904116</td>\n",
       "      <td>2022-11-25 04:32:27</td>\n",
       "      <td>2022-12-30 15:22:04</td>\n",
       "      <td>2022-12-30 15:22:04</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0065077430527166987904116</td>\n",
       "      <td>2022-11-25 04:32:27</td>\n",
       "      <td>2022-12-03 18:39:32</td>\n",
       "      <td>2022-12-03 18:39:32</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0065077430527166987904116</td>\n",
       "      <td>2022-11-25 04:32:27</td>\n",
       "      <td>2022-12-08 07:48:50</td>\n",
       "      <td>2022-12-08 07:48:50</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0065077430527166987904116</td>\n",
       "      <td>2022-11-25 04:32:27</td>\n",
       "      <td>2022-12-27 20:48:01</td>\n",
       "      <td>2022-12-27 20:48:01</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0065077430527166987904116</td>\n",
       "      <td>2022-11-25 04:32:27</td>\n",
       "      <td>2022-12-19 14:00:11</td>\n",
       "      <td>2022-12-19 14:00:11</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0065077430527166987904116</td>\n",
       "      <td>2022-11-25 04:32:27</td>\n",
       "      <td>2022-12-05 17:10:21</td>\n",
       "      <td>2022-12-05 17:10:21</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0065077430527166987904116</td>\n",
       "      <td>2022-11-25 04:32:27</td>\n",
       "      <td>2023-01-28 17:40:08</td>\n",
       "      <td>2023-01-28 17:40:08</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0065077430527166987904116</td>\n",
       "      <td>2022-11-25 04:32:27</td>\n",
       "      <td>2022-11-22 04:58:09</td>\n",
       "      <td>2023-02-01 00:00:00</td>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0065077430527166987904116</td>\n",
       "      <td>2022-11-25 04:32:27</td>\n",
       "      <td>2023-01-07 20:07:19</td>\n",
       "      <td>2023-01-07 20:07:19</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0065077430527166987904116</td>\n",
       "      <td>2022-11-25 04:32:27</td>\n",
       "      <td>2023-01-26 18:07:48</td>\n",
       "      <td>2023-01-26 18:07:48</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0065077430527166987904116</td>\n",
       "      <td>2022-11-25 04:32:27</td>\n",
       "      <td>2023-01-12 21:31:10</td>\n",
       "      <td>2023-01-12 21:31:10</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0065077430527166987904116</td>\n",
       "      <td>2022-11-25 04:32:27</td>\n",
       "      <td>2023-01-20 00:29:06</td>\n",
       "      <td>2023-01-20 00:29:06</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0065077430527166987904116</td>\n",
       "      <td>2022-11-25 04:32:27</td>\n",
       "      <td>2022-11-05 22:04:59</td>\n",
       "      <td>2023-02-01 00:00:00</td>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0065077430527166987904116</td>\n",
       "      <td>2022-11-25 04:32:27</td>\n",
       "      <td>2022-11-17 22:39:16</td>\n",
       "      <td>2023-02-01 00:00:00</td>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0065077430527166987904116</td>\n",
       "      <td>2022-11-25 04:32:27</td>\n",
       "      <td>2023-01-06 21:29:15</td>\n",
       "      <td>2023-01-06 21:29:15</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0065077430527166987904116</td>\n",
       "      <td>2022-11-25 04:32:27</td>\n",
       "      <td>2022-12-10 22:19:13</td>\n",
       "      <td>2022-12-10 22:19:13</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0065077430527166987904116</td>\n",
       "      <td>2022-11-25 04:32:27</td>\n",
       "      <td>2022-12-17 20:31:35</td>\n",
       "      <td>2022-12-17 20:31:35</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0065077430527166987904116</td>\n",
       "      <td>2022-11-25 04:32:27</td>\n",
       "      <td>2022-12-23 23:03:03</td>\n",
       "      <td>2022-12-23 23:03:03</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0065077430527166987904116</td>\n",
       "      <td>2022-11-25 04:32:27</td>\n",
       "      <td>2023-01-01 02:53:35</td>\n",
       "      <td>2023-01-01 02:53:35</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0065077430527166987904116</td>\n",
       "      <td>2022-11-25 04:32:27</td>\n",
       "      <td>2022-12-04 17:13:01</td>\n",
       "      <td>2022-12-04 17:13:01</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               final_anon_mdn           timestamp          event_time  \\\n",
       "0   0009199021916181057050608 2022-11-08 09:38:12 2022-12-02 19:58:09   \n",
       "1   0009199021916181057050608 2022-11-08 09:38:12 2022-11-07 20:41:35   \n",
       "2   0009199021916181057050608 2022-11-08 09:38:12 2022-12-30 18:43:51   \n",
       "3   0009199021916181057050608 2022-11-08 09:38:12 2022-11-20 16:05:31   \n",
       "4   0009199021916181057050608 2022-11-08 09:38:12 2022-11-16 16:41:17   \n",
       "5   0009199021916181057050608 2022-11-08 09:38:12 2022-12-08 11:12:38   \n",
       "6   0009199021916181057050608 2022-11-08 09:38:12 2022-12-27 13:52:08   \n",
       "7   0009199021916181057050608 2022-11-08 09:38:12 2022-12-05 14:22:23   \n",
       "8   0009199021916181057050608 2022-11-08 09:38:12 2022-11-10 21:26:31   \n",
       "9   0009199021916181057050608 2022-11-08 09:38:12 2022-12-16 16:18:18   \n",
       "10  0009199021916181057050608 2022-11-08 09:38:12 2022-11-05 18:27:18   \n",
       "11  0009199021916181057050608 2022-11-08 09:38:12 2022-12-13 22:02:31   \n",
       "12  0009199021916181057050608 2022-11-08 09:38:12 2022-12-17 13:16:38   \n",
       "13  0009199021916181057050608 2022-11-08 09:38:12 2023-01-01 16:21:26   \n",
       "14  0009199021916181057050608 2022-11-08 09:38:12 2022-12-15 22:04:33   \n",
       "15  0009199021916181057050608 2022-11-08 09:38:12 2022-12-20 23:27:15   \n",
       "16  0009199021916181057050608 2022-11-08 09:38:12 2022-11-27 17:06:07   \n",
       "17  0009199021916181057050608 2022-11-08 09:38:12 2023-01-03 16:11:52   \n",
       "18  0009199021916181057050608 2022-11-08 09:38:12 2022-12-11 22:39:33   \n",
       "19  0009199021916181057050608 2022-11-08 09:38:12 2022-11-03 20:23:26   \n",
       "20  0042093647936468925916828 2022-11-22 13:03:39 2023-01-20 23:01:40   \n",
       "21  0042093647936468925916828 2022-11-22 13:03:39 2022-12-07 23:25:00   \n",
       "22  0042093647936468925916828 2022-11-22 13:03:39 2022-11-06 15:28:40   \n",
       "23  0042093647936468925916828 2022-11-22 13:03:39 2022-11-01 18:34:59   \n",
       "24  0042093647936468925916828 2022-11-22 13:03:39 2022-11-28 22:12:48   \n",
       "25  0042093647936468925916828 2022-11-22 13:03:39 2022-12-05 22:37:17   \n",
       "26  0042093647936468925916828 2022-11-22 13:03:39 2022-12-12 23:03:02   \n",
       "27  0042093647936468925916828 2022-11-22 13:03:39 2022-12-24 17:07:25   \n",
       "28  0042093647936468925916828 2022-11-22 13:03:39 2023-01-05 12:29:56   \n",
       "29  0042093647936468925916828 2022-11-22 13:03:39 2023-01-26 04:44:20   \n",
       "30  0042093647936468925916828 2022-11-22 13:03:39 2022-11-14 23:03:10   \n",
       "31  0042093647936468925916828 2022-11-22 13:03:39 2022-12-18 15:07:01   \n",
       "32  0042093647936468925916828 2022-11-22 13:03:39 2022-11-19 20:15:59   \n",
       "33  0042093647936468925916828 2022-11-22 13:03:39 2022-12-16 14:10:03   \n",
       "34  0042093647936468925916828 2022-11-22 13:03:39 2023-01-19 00:23:40   \n",
       "35  0042093647936468925916828 2022-11-22 13:03:39 2023-01-07 00:05:02   \n",
       "36  0042093647936468925916828 2022-11-22 13:03:39 2022-11-11 16:23:23   \n",
       "37  0042093647936468925916828 2022-11-22 13:03:39 2022-11-02 12:03:39   \n",
       "38  0042093647936468925916828 2022-11-22 13:03:39 2023-01-08 01:30:06   \n",
       "39  0042093647936468925916828 2022-11-22 13:03:39 2022-12-06 23:58:37   \n",
       "40  0042093647936468925916828 2022-11-22 13:03:39 2022-11-13 20:15:56   \n",
       "41  0042093647936468925916828 2022-11-22 13:03:39 2023-01-27 20:33:02   \n",
       "42  0042093647936468925916828 2022-11-22 13:03:39 2022-12-14 23:22:12   \n",
       "43  0042093647936468925916828 2022-11-22 13:03:39 2023-01-24 22:50:17   \n",
       "44  0042093647936468925916828 2022-11-22 13:03:39 2023-01-03 19:04:29   \n",
       "45  0042093647936468925916828 2022-11-22 13:03:39 2022-12-11 14:45:34   \n",
       "46  0042093647936468925916828 2022-11-22 13:03:39 2022-11-03 11:28:55   \n",
       "47  0042093647936468925916828 2022-11-22 13:03:39 2022-11-03 22:44:33   \n",
       "48  0056047737941475902994905 2022-11-25 20:06:08                 NaT   \n",
       "49  0065077430527166987904116 2022-11-25 04:32:27 2022-11-01 03:16:42   \n",
       "50  0065077430527166987904116 2022-11-25 04:32:27 2022-12-30 15:22:04   \n",
       "51  0065077430527166987904116 2022-11-25 04:32:27 2022-12-03 18:39:32   \n",
       "52  0065077430527166987904116 2022-11-25 04:32:27 2022-12-08 07:48:50   \n",
       "53  0065077430527166987904116 2022-11-25 04:32:27 2022-12-27 20:48:01   \n",
       "54  0065077430527166987904116 2022-11-25 04:32:27 2022-12-19 14:00:11   \n",
       "55  0065077430527166987904116 2022-11-25 04:32:27 2022-12-05 17:10:21   \n",
       "56  0065077430527166987904116 2022-11-25 04:32:27 2023-01-28 17:40:08   \n",
       "57  0065077430527166987904116 2022-11-25 04:32:27 2022-11-22 04:58:09   \n",
       "58  0065077430527166987904116 2022-11-25 04:32:27 2023-01-07 20:07:19   \n",
       "59  0065077430527166987904116 2022-11-25 04:32:27 2023-01-26 18:07:48   \n",
       "60  0065077430527166987904116 2022-11-25 04:32:27 2023-01-12 21:31:10   \n",
       "61  0065077430527166987904116 2022-11-25 04:32:27 2023-01-20 00:29:06   \n",
       "62  0065077430527166987904116 2022-11-25 04:32:27 2022-11-05 22:04:59   \n",
       "63  0065077430527166987904116 2022-11-25 04:32:27 2022-11-17 22:39:16   \n",
       "64  0065077430527166987904116 2022-11-25 04:32:27 2023-01-06 21:29:15   \n",
       "65  0065077430527166987904116 2022-11-25 04:32:27 2022-12-10 22:19:13   \n",
       "66  0065077430527166987904116 2022-11-25 04:32:27 2022-12-17 20:31:35   \n",
       "67  0065077430527166987904116 2022-11-25 04:32:27 2022-12-23 23:03:03   \n",
       "68  0065077430527166987904116 2022-11-25 04:32:27 2023-01-01 02:53:35   \n",
       "69  0065077430527166987904116 2022-11-25 04:32:27 2022-12-04 17:13:01   \n",
       "\n",
       "    reinbursement_time  date_diff  flag  \n",
       "0  2022-12-02 19:58:09         24     1  \n",
       "1  2023-02-01 00:00:00         84     0  \n",
       "2  2022-12-30 18:43:51         52     0  \n",
       "3  2022-11-20 16:05:31         12     1  \n",
       "4  2022-11-16 16:41:17          8     1  \n",
       "5  2022-12-08 11:12:38         30     1  \n",
       "6  2022-12-27 13:52:08         49     0  \n",
       "7  2022-12-05 14:22:23         27     1  \n",
       "8  2022-11-10 21:26:31          2     1  \n",
       "9  2022-12-16 16:18:18         38     1  \n",
       "10 2023-02-01 00:00:00         84     0  \n",
       "11 2022-12-13 22:02:31         35     1  \n",
       "12 2022-12-17 13:16:38         39     1  \n",
       "13 2023-01-01 16:21:26         54     0  \n",
       "14 2022-12-15 22:04:33         37     1  \n",
       "15 2022-12-20 23:27:15         42     1  \n",
       "16 2022-11-27 17:06:07         19     1  \n",
       "17 2023-01-03 16:11:52         56     0  \n",
       "18 2022-12-11 22:39:33         33     1  \n",
       "19 2023-02-01 00:00:00         84     0  \n",
       "20 2023-01-20 23:01:40         59     0  \n",
       "21 2022-12-07 23:25:00         15     1  \n",
       "22 2023-02-01 00:00:00         70     0  \n",
       "23 2023-02-01 00:00:00         70     0  \n",
       "24 2022-11-28 22:12:48          6     1  \n",
       "25 2022-12-05 22:37:17         13     1  \n",
       "26 2022-12-12 23:03:02         20     1  \n",
       "27 2022-12-24 17:07:25         32     1  \n",
       "28 2023-01-05 12:29:56         43     1  \n",
       "29 2023-01-26 04:44:20         64     0  \n",
       "30 2023-02-01 00:00:00         70     0  \n",
       "31 2022-12-18 15:07:01         26     1  \n",
       "32 2023-02-01 00:00:00         70     0  \n",
       "33 2022-12-16 14:10:03         24     1  \n",
       "34 2023-01-19 00:23:40         57     0  \n",
       "35 2023-01-07 00:05:02         45     1  \n",
       "36 2023-02-01 00:00:00         70     0  \n",
       "37 2023-02-01 00:00:00         70     0  \n",
       "38 2023-01-08 01:30:06         46     0  \n",
       "39 2022-12-06 23:58:37         14     1  \n",
       "40 2023-02-01 00:00:00         70     0  \n",
       "41 2023-01-27 20:33:02         66     0  \n",
       "42 2022-12-14 23:22:12         22     1  \n",
       "43 2023-01-24 22:50:17         63     0  \n",
       "44 2023-01-03 19:04:29         42     1  \n",
       "45 2022-12-11 14:45:34         19     1  \n",
       "46 2023-02-01 00:00:00         70     0  \n",
       "47 2023-02-01 00:00:00         70     0  \n",
       "48 2023-02-01 00:00:00         67     0  \n",
       "49 2023-02-01 00:00:00         67     0  \n",
       "50 2022-12-30 15:22:04         35     1  \n",
       "51 2022-12-03 18:39:32          8     1  \n",
       "52 2022-12-08 07:48:50         13     1  \n",
       "53 2022-12-27 20:48:01         32     1  \n",
       "54 2022-12-19 14:00:11         24     1  \n",
       "55 2022-12-05 17:10:21         10     1  \n",
       "56 2023-01-28 17:40:08         64     0  \n",
       "57 2023-02-01 00:00:00         67     0  \n",
       "58 2023-01-07 20:07:19         43     1  \n",
       "59 2023-01-26 18:07:48         62     0  \n",
       "60 2023-01-12 21:31:10         48     0  \n",
       "61 2023-01-20 00:29:06         55     0  \n",
       "62 2023-02-01 00:00:00         67     0  \n",
       "63 2023-02-01 00:00:00         67     0  \n",
       "64 2023-01-06 21:29:15         42     1  \n",
       "65 2022-12-10 22:19:13         15     1  \n",
       "66 2022-12-17 20:31:35         22     1  \n",
       "67 2022-12-23 23:03:03         28     1  \n",
       "68 2023-01-01 02:53:35         36     1  \n",
       "69 2022-12-04 17:13:01          9     1  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avr_reimbursement.head(70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "increasing-swimming",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>final_anon_mdn</th>\n",
       "      <th>flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000114774094661096041701</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000141208700050020071451</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000148619366931089070772</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0000171673299210037031363</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000173671915411081020422</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0000175041587290050061023</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0000178886770511099080890</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0000193047229701009020370</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0001111643760381032040938</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0001121018354190093090178</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0001126974176240045080842</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0001133314137349033060288</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0001135100823159038020397</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0001142945347800049030270</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0001144253436220006030272</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0001152919638559008040697</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0001156694862089090080340</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0001185757684559065010002</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0001185888515510010020826</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0001193660859650012041381</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               final_anon_mdn  flag\n",
       "0   0000114774094661096041701     1\n",
       "1   0000141208700050020071451     1\n",
       "2   0000148619366931089070772     0\n",
       "3   0000171673299210037031363     1\n",
       "4   0000173671915411081020422     1\n",
       "5   0000175041587290050061023     0\n",
       "6   0000178886770511099080890     1\n",
       "7   0000193047229701009020370     1\n",
       "8   0001111643760381032040938     0\n",
       "9   0001121018354190093090178     1\n",
       "10  0001126974176240045080842     0\n",
       "11  0001133314137349033060288     0\n",
       "12  0001135100823159038020397     1\n",
       "13  0001142945347800049030270     1\n",
       "14  0001144253436220006030272     0\n",
       "15  0001152919638559008040697     1\n",
       "16  0001156694862089090080340     1\n",
       "17  0001185757684559065010002     1\n",
       "18  0001185888515510010020826     0\n",
       "19  0001193660859650012041381     0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avr_reimbursement = avr_reimbursement[['final_anon_mdn', 'flag']].groupby('final_anon_mdn').max().reset_index()\n",
    "avr_reimbursement.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "valuable-computer",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdns = tuple(avr_reimbursement['final_anon_mdn'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "understood-promise",
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o165.collectToPython.\n: org.apache.spark.SparkException: Job 8 cancelled because SparkContext was shut down\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanUpAfterSchedulerStop$1.apply(DAGScheduler.scala:935)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanUpAfterSchedulerStop$1.apply(DAGScheduler.scala:933)\n\tat scala.collection.mutable.HashSet.foreach(HashSet.scala:78)\n\tat org.apache.spark.scheduler.DAGScheduler.cleanUpAfterSchedulerStop(DAGScheduler.scala:933)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onStop(DAGScheduler.scala:2129)\n\tat org.apache.spark.util.EventLoop.stop(EventLoop.scala:84)\n\tat org.apache.spark.scheduler.DAGScheduler.stop(DAGScheduler.scala:2042)\n\tat org.apache.spark.SparkContext$$anonfun$stop$7.apply$mcV$sp(SparkContext.scala:1963)\n\tat org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1388)\n\tat org.apache.spark.SparkContext.stop(SparkContext.scala:1962)\n\tat org.apache.spark.scheduler.cluster.YarnClientSchedulerBackend$MonitorThread.run(YarnClientSchedulerBackend.scala:122)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:740)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2081)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2102)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2121)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2146)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:945)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:944)\n\tat org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:299)\n\tat org.apache.spark.sql.Dataset$$anonfun$collectToPython$1.apply(Dataset.scala:3257)\n\tat org.apache.spark.sql.Dataset$$anonfun$collectToPython$1.apply(Dataset.scala:3254)\n\tat org.apache.spark.sql.Dataset$$anonfun$53.apply(Dataset.scala:3364)\n\tat org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:78)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:125)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:73)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3363)\n\tat org.apache.spark.sql.Dataset.collectToPython(Dataset.scala:3254)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-20226262342d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mWHERE\u001b[0m \u001b[0mid_date\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m'{date_start_reformat}'\u001b[0m \u001b[0mAND\u001b[0m \u001b[0mid_date\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;34m'{date_data_origin_reformat}'\u001b[0m \u001b[0mAND\u001b[0m \u001b[0mfinal_anon_mdn\u001b[0m \u001b[0mIN\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mmdns\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     GROUP BY final_anon_mdn\"\"\"\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoPandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mavr_reimbursement\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavr_reimbursement\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"final_anon_mdn\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'left'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/cloudera/parcels/Anaconda/envs/py36/lib/python3.6/site-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mtoPandas\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2141\u001b[0m         \u001b[0;31m# Below is toPandas without Arrow optimization.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2142\u001b[0;31m         \u001b[0mpdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2144\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/cloudera/parcels/Anaconda/envs/py36/lib/python3.6/site-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mcollect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    531\u001b[0m         \"\"\"\n\u001b[1;32m    532\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSCCallSiteSync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m             \u001b[0msock_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollectToPython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBatchedSerializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPickleSerializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/cloudera/parcels/Anaconda/envs/py36/lib/python3.6/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1305\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1307\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/cloudera/parcels/Anaconda/envs/py36/lib/python3.6/site-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/cloudera/parcels/Anaconda/envs/py36/lib/python3.6/site-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o165.collectToPython.\n: org.apache.spark.SparkException: Job 8 cancelled because SparkContext was shut down\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanUpAfterSchedulerStop$1.apply(DAGScheduler.scala:935)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanUpAfterSchedulerStop$1.apply(DAGScheduler.scala:933)\n\tat scala.collection.mutable.HashSet.foreach(HashSet.scala:78)\n\tat org.apache.spark.scheduler.DAGScheduler.cleanUpAfterSchedulerStop(DAGScheduler.scala:933)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onStop(DAGScheduler.scala:2129)\n\tat org.apache.spark.util.EventLoop.stop(EventLoop.scala:84)\n\tat org.apache.spark.scheduler.DAGScheduler.stop(DAGScheduler.scala:2042)\n\tat org.apache.spark.SparkContext$$anonfun$stop$7.apply$mcV$sp(SparkContext.scala:1963)\n\tat org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1388)\n\tat org.apache.spark.SparkContext.stop(SparkContext.scala:1962)\n\tat org.apache.spark.scheduler.cluster.YarnClientSchedulerBackend$MonitorThread.run(YarnClientSchedulerBackend.scala:122)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:740)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2081)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2102)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2121)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2146)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:945)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:944)\n\tat org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:299)\n\tat org.apache.spark.sql.Dataset$$anonfun$collectToPython$1.apply(Dataset.scala:3257)\n\tat org.apache.spark.sql.Dataset$$anonfun$collectToPython$1.apply(Dataset.scala:3254)\n\tat org.apache.spark.sql.Dataset$$anonfun$53.apply(Dataset.scala:3364)\n\tat org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:78)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:125)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:73)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3363)\n\tat org.apache.spark.sql.Dataset.collectToPython(Dataset.scala:3254)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n"
     ]
    }
   ],
   "source": [
    "for table in tables:\n",
    "    date_start_reformat = date_start.replace('-', '')\n",
    "    date_data_origin_reformat = date_data_origin.replace('-', '')\n",
    "\n",
    "    table_desc = spark.sql(f\"DESCRIBE tel_test_avrd.{table}\")\n",
    "    col_list = [col for col in table_desc.toPandas()['col_name'] if col not in {'id_date', '# col_name', \n",
    "                                                                                '# Partition Information', 'final_anon_mdn', \n",
    "                                                                                'id_date'}]\n",
    "\n",
    "    variables = \"\"\n",
    "    for col in col_list:\n",
    "        variables += f\", SUM({col}) AS sum_{col}, MAX({col}) AS max_{col}, MIN({col}) AS min_{col}, VARIANCE({col}) AS var_{col}, SUM(CASE WHEN {col} > 0 THEN 1 ELSE 0 END) AS cnt_{col}\"\n",
    "    \n",
    "    query = f\"\"\"SELECT final_anon_mdn {variables}, DATEDIFF('{date_start}', CONCAT(SUBSTRING(MAX(id_date), 1, 4), '-', SUBSTRING(MAX(id_date), 5, 2), '-', SUBSTRING(MAX(id_date), 7, 2))) AS recency_{table} \n",
    "    FROM tel_test_avrd.{table} \n",
    "    WHERE id_date < '{date_start_reformat}' AND id_date >= '{date_data_origin_reformat}' AND final_anon_mdn IN {mdns} \n",
    "    GROUP BY final_anon_mdn\"\"\"\n",
    "    data = spark.sql(query).toPandas()\n",
    "    avr_reimbursement = avr_reimbursement.merge(data, on=\"final_anon_mdn\", how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "checked-nebraska",
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o165.collectToPython.\n: org.apache.spark.SparkException: Job 7 cancelled because SparkContext was shut down\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanUpAfterSchedulerStop$1.apply(DAGScheduler.scala:935)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanUpAfterSchedulerStop$1.apply(DAGScheduler.scala:933)\n\tat scala.collection.mutable.HashSet.foreach(HashSet.scala:78)\n\tat org.apache.spark.scheduler.DAGScheduler.cleanUpAfterSchedulerStop(DAGScheduler.scala:933)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onStop(DAGScheduler.scala:2129)\n\tat org.apache.spark.util.EventLoop.stop(EventLoop.scala:84)\n\tat org.apache.spark.scheduler.DAGScheduler.stop(DAGScheduler.scala:2042)\n\tat org.apache.spark.SparkContext$$anonfun$stop$7.apply$mcV$sp(SparkContext.scala:1963)\n\tat org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1388)\n\tat org.apache.spark.SparkContext.stop(SparkContext.scala:1962)\n\tat org.apache.spark.scheduler.cluster.YarnClientSchedulerBackend$MonitorThread.run(YarnClientSchedulerBackend.scala:122)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:740)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2081)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2102)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2121)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2146)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:945)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:944)\n\tat org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:299)\n\tat org.apache.spark.sql.Dataset$$anonfun$collectToPython$1.apply(Dataset.scala:3257)\n\tat org.apache.spark.sql.Dataset$$anonfun$collectToPython$1.apply(Dataset.scala:3254)\n\tat org.apache.spark.sql.Dataset$$anonfun$53.apply(Dataset.scala:3364)\n\tat org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:78)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:125)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:73)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3363)\n\tat org.apache.spark.sql.Dataset.collectToPython(Dataset.scala:3254)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m/opt/cloudera/parcels/Anaconda/envs/py36/lib/python3.6/site-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mtoPandas\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2141\u001b[0m         \u001b[0;31m# Below is toPandas without Arrow optimization.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2142\u001b[0;31m         \u001b[0mpdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2144\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/cloudera/parcels/Anaconda/envs/py36/lib/python3.6/site-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mcollect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    531\u001b[0m         \"\"\"\n\u001b[1;32m    532\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSCCallSiteSync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m             \u001b[0msock_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollectToPython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBatchedSerializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPickleSerializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/cloudera/parcels/Anaconda/envs/py36/lib/python3.6/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1305\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1307\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/cloudera/parcels/Anaconda/envs/py36/lib/python3.6/site-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/cloudera/parcels/Anaconda/envs/py36/lib/python3.6/site-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o165.collectToPython.\n: org.apache.spark.SparkException: Job 7 cancelled because SparkContext was shut down\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanUpAfterSchedulerStop$1.apply(DAGScheduler.scala:935)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanUpAfterSchedulerStop$1.apply(DAGScheduler.scala:933)\n\tat scala.collection.mutable.HashSet.foreach(HashSet.scala:78)\n\tat org.apache.spark.scheduler.DAGScheduler.cleanUpAfterSchedulerStop(DAGScheduler.scala:933)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onStop(DAGScheduler.scala:2129)\n\tat org.apache.spark.util.EventLoop.stop(EventLoop.scala:84)\n\tat org.apache.spark.scheduler.DAGScheduler.stop(DAGScheduler.scala:2042)\n\tat org.apache.spark.SparkContext$$anonfun$stop$7.apply$mcV$sp(SparkContext.scala:1963)\n\tat org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1388)\n\tat org.apache.spark.SparkContext.stop(SparkContext.scala:1962)\n\tat org.apache.spark.scheduler.cluster.YarnClientSchedulerBackend$MonitorThread.run(YarnClientSchedulerBackend.scala:122)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:740)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2081)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2102)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2121)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2146)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:945)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:944)\n\tat org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:299)\n\tat org.apache.spark.sql.Dataset$$anonfun$collectToPython$1.apply(Dataset.scala:3257)\n\tat org.apache.spark.sql.Dataset$$anonfun$collectToPython$1.apply(Dataset.scala:3254)\n\tat org.apache.spark.sql.Dataset$$anonfun$53.apply(Dataset.scala:3364)\n\tat org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:78)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:125)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:73)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3363)\n\tat org.apache.spark.sql.Dataset.collectToPython(Dataset.scala:3254)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "k = 3 \n",
    "\n",
    "date_start = dates[k]\n",
    "date_end = dates[k+1]\n",
    "date_final_obs = dates[k+3]\n",
    "date_data_origin = dates[k-3]\n",
    "\n",
    "exp_sdp_remboursement_recharge_v2 = spark.sql(f\"\"\"SELECT * \n",
    "FROM \n",
    "tel_test_avrd.exp_sdp_remboursement_recharge_v2 \n",
    "WHERE event_time >= '{date_start}' AND event_time < '{date_final_obs}'\"\"\")\n",
    "\n",
    "exp_sdp_avr_v2 = spark.sql(f\"\"\"SELECT * \n",
    "FROM tel_test_avrd.exp_sdp_avr_v2 \n",
    "WHERE timestamp >= '{date_start}' AND timestamp < '{date_end}' \n",
    "ORDER BY RAND() LIMIT 100000\"\"\")\n",
    "\n",
    "avr_reimbursement = exp_sdp_avr_v2.join(exp_sdp_remboursement_recharge_v2, 'final_anon_mdn', how='left').select('final_anon_mdn', 'timestamp', 'event_time').toPandas()\n",
    "\n",
    "avr_reimbursement['timestamp'] = pd.to_datetime(avr_reimbursement['timestamp'])\n",
    "avr_reimbursement['reinbursement_time'] = avr_reimbursement.apply(\n",
    "    lambda row: date_final_obs if (pd.isnull(row['event_time']) or row['event_time'] < row['timestamp']) \n",
    "    else row['event_time'], axis=1)\n",
    "\n",
    "avr_reimbursement['date_diff'] = pd.to_datetime(avr_reimbursement['reinbursement_time']) - pd.to_datetime(avr_reimbursement['timestamp'])\n",
    "avr_reimbursement['date_diff'] = avr_reimbursement['date_diff'].dt.days\n",
    "avr_reimbursement['flag'] = (avr_reimbursement['date_diff'] <= 45).astype(int)\n",
    "avr_reimbursement = avr_reimbursement[['final_anon_mdn', 'flag']].groupby('final_anon_mdn').max().reset_index()\n",
    "\n",
    "mdns = tuple(avr_reimbursement['final_anon_mdn'].tolist())\n",
    "\n",
    "for table in tables:\n",
    "    date_start_reformat = date_start.replace('-', '')\n",
    "    date_data_origin_reformat = date_data_origin.replace('-', '')\n",
    "\n",
    "    table_desc = spark.sql(f\"DESCRIBE tel_test_avrd.{table}\")\n",
    "    col_list = [col for col in table_desc.toPandas()['col_name'] if col not in {'id_date', '# col_name', '# Partition Information', 'final_anon_mdn', 'id_date'}]\n",
    "\n",
    "    variables = \"\"\n",
    "    for col in col_list:\n",
    "        variables += f\", SUM({col}) AS sum_{col}, MAX({col}) AS max_{col}, MIN({col}) AS min_{col}, VARIANCE({col}) AS var_{col}, SUM(CASE WHEN {col} > 0 THEN 1 ELSE 0 END) AS cnt_{col}\"\n",
    "    \n",
    "    query = f\"\"\"SELECT final_anon_mdn {variables}, DATEDIFF('{date_start}', CONCAT(SUBSTRING(MAX(id_date), 1, 4), '-', SUBSTRING(MAX(id_date), 5, 2), '-', SUBSTRING(MAX(id_date), 7, 2))) AS recency_{table} \n",
    "    FROM tel_test_avrd.{table} \n",
    "    WHERE id_date < '{date_start_reformat}' AND id_date >= '{date_data_origin_reformat}' AND final_anon_mdn IN {mdns} \n",
    "    GROUP BY final_anon_mdn\"\"\"\n",
    "    data = spark.sql(query).toPandas()\n",
    "    avr_reimbursement = avr_reimbursement.merge(data, on=\"final_anon_mdn\", how='left')\n",
    "\n",
    "query = f\"\"\"SELECT \n",
    "final_anon_mdn, \n",
    "COUNT(1) AS cnt_req_avr, \n",
    "SUM(CASE WHEN reason_of_failure = 'Success' AND grantedadvance IS NOT NULL THEN 1 ELSE 0 END) AS cnt_success_avr \n",
    "FROM tel_test_avrd.exp_sdp_avr_v2 \n",
    "WHERE timestamp < '{date_start}' AND final_anon_mdn IN {mdns} \n",
    "GROUP BY final_anon_mdn\"\"\"\n",
    "\n",
    "avr = spark.sql(query).toPandas()\n",
    "avr_reimbursement = avr_reimbursement.merge(avr, on=\"final_anon_mdn\", how='left')\n",
    "\n",
    "file_name = f'data_{date_start}.csv'\n",
    "avr_reimbursement.to_csv(file_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noted-quarter",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
